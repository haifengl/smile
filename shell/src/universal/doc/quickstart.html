<!-- prettify js and CSS -->
<script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js?lang=scala"></script>

<!-- scroll/follow sidebar -->
<script src="js/follow-sidebar.js" type="text/javascript"></script>

<div class="col-md-3 col-md-push-9 hidden-xs hidden-sm">
    <div id="sidebar">
        <div class="sidebar-toc" style="margin-bottom: 20px;">
            <p class="toc-header">Contents</p>
            <div id="toc"></div>
        </div>
        <div id="search">
            <script>
                (function() {
                    var cx = '010264411143030149390:ajvee_ckdzs';
                    var gcse = document.createElement('script');
                    gcse.type = 'text/javascript';
                    gcse.async = true;
                    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
                            '//cse.google.com/cse.js?cx=' + cx;
                    var s = document.getElementsByTagName('script')[0];
                    s.parentNode.insertBefore(gcse, s);
                })();
            </script>
            <gcse:searchbox-only></gcse:searchbox-only>
        </div>
    </div>
</div>

<div class="col-md-9 col-md-pull-3">
    <h1 id="quickstart-top" class="title">Quick Start</h1>

    <p>Smile is a fast and comprehensive machine learning system.
        With advanced data structures and algorithms, Smile delivers the state-of-art performance.
        Smile is self contained and requires only Java standard library.
        It also provides high-level operators in Scala and an interactive shell.
        In practice, data scientists usually build models with high-level tools such as R, Matlab,
        SAS, etc. However, developers have to spend a lot of time and energy to incorporate these
        models in the production system that are often implemented in general purpose programming
        languages such as Java and Scala. With Smile, data scientists and developers can work
        in the same environment to build machine learning applications quickly!</p>

    <h2 id="download">Download</h2>

    <p>Get Smile from the <a href="https://github.com/haifengl/smile/releases">releases page</a> of
        the project website. Downloads are pre-packaged for Mac, Windows, and universal tarball.</p>

    <p>If you would like to build Smile from source, please first install Java, Scala and SBT.
        Smile uses <a href="http://www.scala-sbt.org/sbt-pgp/">sbt-pgp</a> plugin when
        publishing to maven central repository. Although you will not publish the project,
        you still have to set up sbt-pgp in order to build the packages. Fortunately, it is
        very easy. Simply add the following to your <code>~/.sbt/0.13/plugins/gpg.sbt</code> file:</p>

    <pre class="prettyprint lang-scala"><code>
    addSbtPlugin("com.jsuereth" % "sbt-pgp" % "1.0.0")
    </code></pre>

    <p>Then clone the repo and build the package:</p>

    <pre class="prettyprint lang-bash"><code>
    git clone https://github.com/haifengl/smile.git
    cd smile
    sbt package
    </code></pre>

    <p>To test the latest code, run the following</p>

    <pre class="prettyprint lang-bash"><code>
    git pull
    ./smile.sh
    </code></pre>

    <p>which will build the system and enter the shell.</p>

    <p>Smile runs on both Windows and UNIX-like systems (e.g. Linux, Mac OS).
        All you need is to have <code>Java</code> installed on your system <code>PATH</code>,
        or the <code>JAVA_HOME</code> environment variable pointing to a Java installation.</p>

    <p>The download packages of Smile are built on Java 8. But Java 7 is sufficient to build it
        if needed. For the Scala API, we uses Scala 2.11.</p>

    <h2 id="shell">Shell</h2>

    <p>Smile comes with an interactive shell. In the home directory of Smile, type</p>

    <pre class="prettyprint lang-bash"><code>
    ./bin/smile
    </code></pre>

    <p>to enter the shell, which is based on <a href="http://www.scala-lang.org">Scala</a>
        interpreter. So you can run any valid Scala
        expressions in the shell. In the simplest case, you can use it as a calculator.
        Besides, all high-level Smile operators are predefined
        in the shell. Be default, the shell uses up to 4GB memory. If you need more memory
        to handle large data, use the option <code>-J-Xmx</code>. For example,</p>

    <pre class="prettyprint lang-bash"><code>
    ./bin/smile -J-Xmx8192M
    </code></pre>

    <p>You can also modify the configuration file <code>./conf/application.ini</code>
        for the memory and other JVM settings.</p>

    <p>In the shell, type <code>:help</code> to print Scala interpreter help
        information. To get help information of Smile high-level operators,
        the <code>help</code>. You can also get detailed information on
        each operator by typing <code>help("command")</code>, e.g.
        <code>help("svm")</code>. To exit the shell, type <code>:quit</code>.</p>

    <p>In the shell, type <code>demo</code> to bring up the demo window,
        which shows off various Smile's machine learning capabilities.</p>

    <p>You can also type <code>benchmark()</code> to see Smile's performance
        on a couple of test data. You can run a particular benchmark by
        <code>bencharm("test name")</code>, where test name could be "airline",
        "usps", etc.</p>

    <p>In the <code>data</code> directory, we also include many open datasets,
        which are frequently used in research and benchmark. Now let&#8217;s build
        a classification model with Smile. It is as easy as</p>

    <pre class="prettyprint lang-scala"><code>
    val data = readArff("data/weka/iris.arff", 4)
    val (x, y) = data.unzipInt

    val rf = randomForest(x, y)
    println(s"OOB error = ${rf.error}")
    rf.predict(x(0))
    </code></pre>

    <p>In this example, we use the famous Iris data from R.A. Fisher. The data
        is in Weka's ARFF format. The second parameter of readArff is the column index
        of response variable. With our parsers, the column index starts with 0. The
        function readArff returns an object of <code>AttributeDataset</code>.
        Besides the data itself, an <code>AttributeDataset</code> object also contains many meta data.
        Then we use the help function <code>unzipInt</code> to get the training
        data and labels. For regression, you may use <code>unzipDouble</code> as
        the response variable is real value. Finally, we train a random forest
        with default parameters and print out its OOB (out of bag) error. We can apply
        the model on new data samples with the method <code>predict</code>.</p>

    <div id="btnv">
        <a class="btn-next-text" id="overview" href="#" title="Next Section: Overview"><span>Overview</span></a>
        <span class="btn-arrow-right">&nbsp;&rarr;</span>
    </div>
</div>

<script type="text/javascript">
    $('#toc').toc({exclude: 'h1, h5, h6', context: '', autoId: true, numerate: false});
</script>